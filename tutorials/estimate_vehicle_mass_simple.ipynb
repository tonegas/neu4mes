{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASwLGl2YbJ0s"
   },
   "source": [
    "# **Estimation of the vehicle mass with neural recursive least squares**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "116_OsEE6s0g"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93483,
     "status": "ok",
     "timestamp": 1662369075489,
     "user": {
      "displayName": "Sebastiano Taddei",
      "userId": "13808977505290533085"
     },
     "user_tz": -120
    },
    "id": "xj7-b68D6wDf",
    "outputId": "37b89aca-5ca5-4ce6-887c-13cd411b4d98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  /Users/mattiapiccinini/Documents/Research/Neu4Mes/Neu4Mes/tutorials\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "print('Current working directory: ',os.getcwd())\n",
    "sys.path.append(os.path.join(os.getcwd(),'..'))\n",
    "from neu4mes import *\n",
    "from neu4mes import relation\n",
    "from neu4mes import earlystopping\n",
    "relation.NeuObj_names = []  # reset the list of NeuObj names\n",
    "\n",
    "# import a library for plots\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "#mpl.rcParams['text.usetex'] = True\n",
    "import matplotlib.pyplot as plt\n",
    "plt.close('all')\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 22\n",
    "BIGGER_SIZE = 26\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)     # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rc('grid', linestyle=\"--\", color='grey')\n",
    "\n",
    "# enable zooming on the plots\n",
    "%matplotlib inline\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations and known constant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data folder\n",
    "data_folder = os.path.join(os.getcwd(),'datasets','estimate_vehicle_mass')\n",
    "\n",
    "# Import the file with the vehicle data\n",
    "vehicle_data_csv = os.path.join(data_folder,'other_data','vehicle_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom parametric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# Absolute value function\n",
    "# -------------------------------------------------\n",
    "def abs_fun(x):\n",
    "  return torch.abs(x)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Saturation function\n",
    "# -------------------------------------------------\n",
    "def sat_fun(x,x_min,x_max):\n",
    "  return torch.min(torch.max(x,x_min),x_max)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Lateral force model (pseudo-neural)\n",
    "# -------------------------------------------------\n",
    "def Fy_model(ay, ax,      # inputs\n",
    "             ay_0, ax_0,  # constants (centers of this local model)\n",
    "             weights      # learnable array of weights\n",
    "             ):\n",
    "  sign_ay = torch.sign(ay)  # sign of the lateral acceleration\n",
    "\n",
    "  # weights defining the local model for ay\n",
    "  qy_1 = weights[0,0,0]\n",
    "  qy_2 = weights[0,0,1]\n",
    "  qy_3 = weights[0,0,2]\n",
    "  qy_4 = weights[0,0,3]\n",
    "  qy_5 = weights[0,0,4]\n",
    "  qy_6 = weights[0,0,5]\n",
    "  # weights defining the local model for ax\n",
    "  qx_1 = weights[0,0,6]\n",
    "  qx_2 = weights[0,0,7]\n",
    "  qx_3 = weights[0,0,8]\n",
    "  qx_4 = weights[0,0,9]\n",
    "  qx_5 = weights[0,0,10]\n",
    "  qx_6 = weights[0,0,11]\n",
    "  qx_7 = weights[0,0,12]\n",
    "\n",
    "  # model output\n",
    "  output = (qy_1 + qy_2*(ay - ay_0*sign_ay) + qx_1*(ax - ax_0) + qx_2*torch.pow(ax - ax_0,2) + \\\n",
    "            qy_3*qx_3*(ay - (qy_4+ay_0)*sign_ay)*(qx_4 + ax - ax_0)) * \\\n",
    "           (1 + qy_5*(ay - ay_0*sign_ay) + qx_5*(ax - ax_0) + qx_6*torch.pow(ax - ax_0,2) + \\\n",
    "            qy_6*qx_7*(ay - ay_0*sign_ay)*(ax - ax_0)) \n",
    "  return output\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Rolling resistance model (pseudo-neural)\n",
    "# -------------------------------------------------\n",
    "def Fr_model(vx, ay, ax,  # inputs\n",
    "             ay_0, ax_0,  # constants (centers of this local model)\n",
    "             weights      # learnable array of weights\n",
    "            ):\n",
    "  sign_ay = torch.sign(ay)  # sign of the lateral acceleration\n",
    "\n",
    "  # weights defining the local model for ay\n",
    "  fv_1 = weights[0,0,0]\n",
    "  fv_2 = weights[0,0,1]\n",
    "  s_0  = weights[0,0,2]\n",
    "  sy_1 = weights[0,0,3]\n",
    "  # weights defining the local model for ax\n",
    "  sx_1 = weights[0,0,4]\n",
    "\n",
    "  # local model formulation\n",
    "  f_r = 1.0 + fv_1*vx + fv_2*torch.pow(vx,2)  # rolling resistance coefficient\n",
    "  F_z = s_0 + sx_1*(ax - ax_0) + sy_1*(ay - ay_0*sign_ay)  # vertical force\n",
    "  output = f_r*F_z\n",
    "  return output\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Regressors model for recursive least squares, \n",
    "# where y = Phi*b (b = vehicle mass)\n",
    "# -------------------------------------------------\n",
    "def Phi_model(theta, ax,   # inputs\n",
    "              g,           # constant (gravitational acceleration)\n",
    "              c_r          # learnable parameter (rolling resist. coeff.)\n",
    "              ):\n",
    "  output = ax + g*torch.sin(theta) + c_r*g*torch.cos(theta)\n",
    "  return output\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Measurement model for recursive least squares, \n",
    "# where y = Phi*b (b = vehicle mass)\n",
    "# -------------------------------------------------\n",
    "def y_model(Tyf_engine, Tyf_brake, Tyr_brake, vx, ax,  # inputs\n",
    "            I_wf, I_wr, r_f, r_r, i_gear,              # constants\n",
    "            c_v, k_d                                   # learnable parameters (linear and quadratic drag)\n",
    "            ):\n",
    "  # wheel torques\n",
    "  T_yf_traction = Tyf_engine*i_gear\n",
    "  T_yf = T_yf_traction - Tyf_brake\n",
    "  T_yr = -Tyr_brake\n",
    "\n",
    "  # analytical model formulation, based on the longitudinal vehicle dynamics\n",
    "  analytical_model = (-2*I_wf*ax/r_f + T_yf)/r_f + \\\n",
    "                     (-2*I_wr*ax/r_r + T_yr)/r_r - c_v*vx - k_d*torch.pow(vx,2)\n",
    "\n",
    "  # output of the layer\n",
    "  output = analytical_model\n",
    "  return output\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Neural RLS update for the vehicle mass estimate \n",
    "# and the covariance of the estimation error\n",
    "# -------------------------------------------------\n",
    "def RLS_update(m,    # vehicle mass estimate at the previous time step\n",
    "               P,    # covariance of the estimation error at the previous time step\n",
    "               Phi,  # regressor at the current time step\n",
    "               y,    # measurement model at the current time step\n",
    "               Tyf_engine, Tyf_brake, vx,  # inputs\n",
    "               i_gear, lambda_forget,  # constants\n",
    "               Tyf_min_thresh_pos, Tyf_min_thresh_neg, vx_min_thresh, reg_fact,  # constants\n",
    "               ):\n",
    "  # compute the total torque at the front wheels\n",
    "  Tyf = Tyf_engine*i_gear - Tyf_brake\n",
    "\n",
    "  # compute the Kalman gain\n",
    "  L = P*Phi / (lambda_forget + Phi*P*Phi)\n",
    "\n",
    "  # update the covariance matrix\n",
    "  P_update = (1/lambda_forget) * (P - L*Phi*P)\n",
    "\n",
    "  # validity functions to freeze the mass estimate:\n",
    "  # validity function for the wheel torque: it goes to 0 when Tyf is in [Tyf_min_thresh_neg,Tyf_min_thresh_pos], and 1 otherwise\n",
    "  validity_fun_Tyf = 1.0 + (torch.sin(torch.atan((Tyf-Tyf_min_thresh_pos)/reg_fact))+1.0)/2.0 - \\\n",
    "                           (torch.sin(torch.atan((Tyf-Tyf_min_thresh_neg)/reg_fact))+1.0)/2.0\n",
    "  # vality function for the vehicle speed: it goes to 0 when vx is below vx_min_thresh, and 1 otherwise\n",
    "  validity_fun_vx = (torch.sin(torch.atan((vx-vx_min_thresh)/reg_fact))+1.0)/2.0\n",
    "  # overall validity function\n",
    "  validity_fun = validity_fun_Tyf * validity_fun_vx\n",
    "\n",
    "  # update the vehicle mass estimate\n",
    "  m_update = m + L*(y - Phi*m)*validity_fun\n",
    "\n",
    "  # return the updated mass estimate and the updated covariance:\n",
    "  # concatenate the two tensors along the third dimension, but do not add a new dimension\n",
    "  out_tensor = torch.cat((m_update,P_update),dim=2)\n",
    "  return out_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing to compute auxiliary quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders containing the training and validation data\n",
    "data_folder_train = os.path.join(data_folder,'training')\n",
    "data_folder_valid = os.path.join(data_folder,'validation')\n",
    "\n",
    "# Load the training data\n",
    "train_data = pd.read_csv(os.path.join(data_folder_train,'train_data.csv'))\n",
    "\n",
    "# Compute the min and max values of the signals from the training set:\n",
    "# Lateral acceleration\n",
    "max_ay = np.percentile(abs(train_data['ay'].values),99.9,axis=0).item()\n",
    "\n",
    "# Longitudinal speed\n",
    "vx_min_thresh = 4.0  # [m/s] minimum vehicle speed threshold, below which the mass estimation is frozen\n",
    "min_vx = np.max([vx_min_thresh, np.min(train_data['vx'])]).item()\n",
    "max_vx = np.max(train_data['vx']).item()\n",
    "\n",
    "# Longitudinal acceleration\n",
    "min_ax = np.percentile(train_data['ax'],0.1,axis=0).item()\n",
    "max_ax = np.percentile(train_data['ax'],99.9,axis=0).item()\n",
    "\n",
    "# Steering angle and torques\n",
    "max_steer      = np.percentile(abs(train_data['steer']),99.9,axis=0).item()\n",
    "max_Tyf_engine = np.percentile(train_data['Tyf_engine'],99.9,axis=0).item()\n",
    "max_Tyf_brake  = np.percentile(train_data['Tyf_brake'],99.9,axis=0).item()\n",
    "max_Tyr_brake  = np.percentile(train_data['Tyr_brake'],99.9,axis=0).item()\n",
    "\n",
    "flag_print_min_max_values = False\n",
    "if flag_print_min_max_values:\n",
    "  print('max_ay:\\t\\t',max_ay,' [m/s^2]')\n",
    "  print('min_vx:\\t\\t',min_vx,' [m/s]')\n",
    "  print('max_vx:\\t\\t',max_vx,' [m/s]')\n",
    "  print('min_ax:\\t\\t',min_ax,' [m/s^2]')\n",
    "  print('max_ax:\\t\\t',max_ax,' [m/s^2]')\n",
    "  print('max_steer:\\t',max_steer,' [rad]')\n",
    "  print('max_Tyf_engine:\\t',max_Tyf_engine,' [Nm]')\n",
    "  print('max_Tyf_brake:\\t',max_Tyf_brake,' [Nm]')\n",
    "  print('max_Tyr_brake:\\t',max_Tyr_brake,' [Nm]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# Local models\n",
    "# -----------------------------------------------\n",
    "# Channels (aka local models) for the lateral acceleration ay\n",
    "num_channels_ay = 5  # number of channels\n",
    "chan_centers_ay = list(np.linspace(0.0, max_ay, num=num_channels_ay)  )  # centers of the channels\n",
    "\n",
    "# Channels for the longitudinal acceleration ax\n",
    "num_channels_ax = 5  # number of channels\n",
    "perc_neg_ax = 0.5 # percentage of channels dedicated to negative ax\n",
    "# Define the center points of the channels (make sure to capture ax = 0)\n",
    "chan_centers_ax = np.linspace(min_ax, 0, num=int(num_channels_ax*perc_neg_ax), endpoint=False)\n",
    "chan_centers_ax = list(np.append(chan_centers_ax, np.linspace(0, max_ax, num=num_channels_ax - int(num_channels_ax*perc_neg_ax))))\n",
    "\n",
    "num_weights_Fy_model = 13  # number of weights in the lateral force model\n",
    "num_weights_Fr_model = 5   # number of weights in the rolling resistance model\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Neurons in fully connected layers\n",
    "# -----------------------------------------------\n",
    "num_neur_FC_1_steer = 10\n",
    "\n",
    "# -----------------------------------------------\n",
    "# RLS parameters\n",
    "# -----------------------------------------------\n",
    "lambda_forget      = 0.995    # forgetting factor for the RLS algorithm\n",
    "Tyf_min_thresh_pos =  200     # [Nm] minimum positive wheel torque threshold for the RLS\n",
    "Tyf_min_thresh_neg = -200     # [Nm] minimum negative wheel torque threshold for the RLS\n",
    "reg_fact           = 3e-2     # regularization factor for smooth functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<neu4mes.relation.Stream at 0x7fabc45e0310>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation.NeuObj_names = []  # reset the list of NeuObj names\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Neural model inputs and outputs\n",
    "# -----------------------------------------------\n",
    "# Inputs\n",
    "Tyf_engine  = Input('Tyf_engine')   # [Nm] engine torque at the front wheels\n",
    "Tyf_brake   = Input('Tyf_brake')    # [Nm] braking torque at the front wheels\n",
    "Tyr_brake   = Input('Tyr_brake')    # [Nm] braking torque at the rear wheels\n",
    "theta       = Input('theta')        # [rad] road slope angle\n",
    "vx          = Input('vx')           # [m/s] longitudinal vehicle velocity\n",
    "ax          = Input('ax')           # [m/s^2] longitudinal vehicle acceleration\n",
    "ay          = Input('ay')           # [m/s^2] lateral vehicle acceleration\n",
    "steer       = Input('steer')        # [rad] steering wheel angle\n",
    "# States\n",
    "m           = State('m')            # [kg] estimated vehicle mass\n",
    "P           = State('P')            # covariance of the mass estimation error\n",
    "# Output\n",
    "m_target    = Input('m_target')     # [kg] real vehicle mass\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Pre-process the inputs\n",
    "# -----------------------------------------------\n",
    "ay_abs = ParamFun(abs_fun)(ay.sw([0,1]))  # absolute value of the lateral acceleration\n",
    "\n",
    "# Saturated inputs\n",
    "Tyf_engine_sat = ParamFun(sat_fun)(Tyf_engine.sw([0,1]),0.0,max_Tyf_engine)\n",
    "Tyf_brake_sat  = ParamFun(sat_fun)(Tyf_brake.sw([0,1]),0.0,max_Tyf_brake)\n",
    "Tyr_brake_sat  = ParamFun(sat_fun)(Tyr_brake.sw([0,1]),0.0,max_Tyr_brake)\n",
    "vx_sat         = ParamFun(sat_fun)(vx.sw([0,1]),min_vx,max_vx)\n",
    "ax_sat         = ParamFun(sat_fun)(ax.sw([0,1]),min_ax,max_ax)\n",
    "ay_sat         = ParamFun(sat_fun)(ay.sw([0,1]),-max_ay,max_ay)\n",
    "abs_ay_sat     = ParamFun(sat_fun)(ay_abs,0.0,max_ay)\n",
    "steer_sat      = ParamFun(sat_fun)(steer.sw([0,1]),-max_steer,max_steer)\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Non-trainable parameters\n",
    "# -----------------------------------------------\n",
    "# Vehicle data\n",
    "I_wf   = Constant('I_wf',values=pd.read_csv(vehicle_data_csv)['I_wf'][0])      # [kg*m^2] front wheel inertia\n",
    "I_wr   = Constant('I_wr',values=pd.read_csv(vehicle_data_csv)['I_wr'][0])      # [kg*m^2] rear wheel inertia\n",
    "r_f    = Constant('r_f',values=pd.read_csv(vehicle_data_csv)['r_f'][0])        # [m] front wheel radius\n",
    "r_r    = Constant('r_r',values=pd.read_csv(vehicle_data_csv)['r_r'][0])        # [m] rear wheel radius\n",
    "i_gear = Constant('i_gear',values=pd.read_csv(vehicle_data_csv)['i_gear'][0])  # [-] transmission gear ratio\n",
    "g      = Constant('g',values=pd.read_csv(vehicle_data_csv)['g'][0])            # [m/s^2] gravitational acceleration\n",
    "\n",
    "# RLS parameters\n",
    "lambda_forget      = Constant('lambda_forget',values=lambda_forget)  # forgetting factor for the RLS algorithm\n",
    "Tyf_min_thresh_pos = Constant('Tyf_min_thresh_pos',values=Tyf_min_thresh_pos)  # Tyf_min_thresh_pos\n",
    "Tyf_min_thresh_neg = Constant('Tyf_min_thresh_neg',values=Tyf_min_thresh_neg)  # Tyf_min_thresh_neg\n",
    "vx_min_thresh      = Constant('vx_min_thresh',values=vx_min_thresh)  # minimum vehicle speed threshold\n",
    "reg_fact           = Constant('reg_fact',values=reg_fact)  # regularization factor for smooth functions\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Regressors model for recursive least squares\n",
    "# -----------------------------------------------\n",
    "# Trainable parameters\n",
    "c_r = Parameter('c_r',values=[[pd.read_csv(vehicle_data_csv)['c_r'][0]]])  # initial guess for the rolling resistance coefficient\n",
    "# Regressors model\n",
    "out_Phi_model = ParamFun(Phi_model,\n",
    "                         constants=[g],\n",
    "                         parameters=[c_r])(theta.sw([0,1]), ax_sat)\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Measurement model for recursive least squares\n",
    "# -----------------------------------------------\n",
    "# Trainable parameters\n",
    "c_v = Parameter('c_v',values=[[pd.read_csv(vehicle_data_csv)['c_v'][0]]])  # initial guess for the linear drag coefficient\n",
    "k_d = Parameter('k_d',values=[[pd.read_csv(vehicle_data_csv)['k_d'][0]]])  # initial guess for the quadratic drag coefficient\n",
    "# Measurement model\n",
    "out_y_model = ParamFun(y_model,\n",
    "                       constants=[I_wf, I_wr, r_f, r_r, i_gear],\n",
    "                       parameters=[c_v,k_d])(Tyf_engine_sat, Tyf_brake_sat, Tyr_brake_sat, vx_sat, ax_sat)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Neural RLS update for the vehicle mass estimate \n",
    "# and the covariance of the estimation error\n",
    "# -------------------------------------------------\n",
    "out_RLS_update = ParamFun(RLS_update,\n",
    "                          constants=[i_gear, lambda_forget, Tyf_min_thresh_pos, Tyf_min_thresh_neg, vx_min_thresh, reg_fact])(\n",
    "                          m.sw([0,1]), P.sw([0,1]), out_Phi_model, out_y_model, Tyf_engine_sat, Tyf_brake_sat, vx_sat)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Model output\n",
    "# -------------------------------------------------\n",
    "# Extract the mass estimate and the covariance of the estimation error\n",
    "m_estim = Select(out_RLS_update,0)\n",
    "P_estim = Select(out_RLS_update,1)\n",
    "\n",
    "# Close the loop\n",
    "m_estim.closedLoop(m)\n",
    "P_estim.closedLoop(P)\n",
    "\n",
    "# m_estim = ClosedLoop(m_estim,m)\n",
    "# P_estim = ClosedLoop(P_estim,P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neu4Mes framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m================================ Neu4mes Model =================================\u001b[0m\n",
      "\u001b[32m{'Constants': {'Constant498': {'dim': 1, 'values': 0.0},\n",
      "               'Constant499': {'dim': 1, 'values': 378.9961321254068},\n",
      "               'Constant503': {'dim': 1, 'values': 0.0},\n",
      "               'Constant504': {'dim': 1, 'values': 3034.740976853754},\n",
      "               'Constant508': {'dim': 1, 'values': 0.0},\n",
      "               'Constant509': {'dim': 1, 'values': 1114.470293868032},\n",
      "               'Constant513': {'dim': 1, 'values': 4.0},\n",
      "               'Constant514': {'dim': 1, 'values': 20.627002395766304},\n",
      "               'Constant518': {'dim': 1, 'values': -1.5607289739112873},\n",
      "               'Constant519': {'dim': 1, 'values': 2.746621294865885},\n",
      "               'I_wf': {'dim': 1, 'values': 2.4},\n",
      "               'I_wr': {'dim': 1, 'values': 2.4},\n",
      "               'Tyf_min_thresh_neg': {'dim': 1, 'values': -200},\n",
      "               'Tyf_min_thresh_pos': {'dim': 1, 'values': 200},\n",
      "               'g': {'dim': 1, 'values': 9.81},\n",
      "               'i_gear': {'dim': 1, 'values': 10.163},\n",
      "               'lambda_forget': {'dim': 1, 'values': 0.995},\n",
      "               'r_f': {'dim': 1, 'values': 0.364},\n",
      "               'r_r': {'dim': 1, 'values': 0.363},\n",
      "               'reg_fact': {'dim': 1, 'values': 0.03},\n",
      "               'vx_min_thresh': {'dim': 1, 'values': 4.0}},\n",
      " 'Functions': {'FParamFun495': {'code': 'def sat_fun(x,x_min,x_max):\\n'\n",
      "                                        '  return '\n",
      "                                        'torch.min(torch.max(x,x_min),x_max)\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 3,\n",
      "                                'name': 'sat_fun',\n",
      "                                'out_dim': {'dim': 1, 'sw': 1},\n",
      "                                'params_and_consts': []},\n",
      "               'FParamFun500': {'code': 'def sat_fun(x,x_min,x_max):\\n'\n",
      "                                        '  return '\n",
      "                                        'torch.min(torch.max(x,x_min),x_max)\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 3,\n",
      "                                'name': 'sat_fun',\n",
      "                                'out_dim': {'dim': 1, 'sw': 1},\n",
      "                                'params_and_consts': []},\n",
      "               'FParamFun505': {'code': 'def sat_fun(x,x_min,x_max):\\n'\n",
      "                                        '  return '\n",
      "                                        'torch.min(torch.max(x,x_min),x_max)\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 3,\n",
      "                                'name': 'sat_fun',\n",
      "                                'out_dim': {'dim': 1, 'sw': 1},\n",
      "                                'params_and_consts': []},\n",
      "               'FParamFun510': {'code': 'def sat_fun(x,x_min,x_max):\\n'\n",
      "                                        '  return '\n",
      "                                        'torch.min(torch.max(x,x_min),x_max)\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 3,\n",
      "                                'name': 'sat_fun',\n",
      "                                'out_dim': {'dim': 1, 'sw': 1},\n",
      "                                'params_and_consts': []},\n",
      "               'FParamFun515': {'code': 'def sat_fun(x,x_min,x_max):\\n'\n",
      "                                        '  return '\n",
      "                                        'torch.min(torch.max(x,x_min),x_max)\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 3,\n",
      "                                'name': 'sat_fun',\n",
      "                                'out_dim': {'dim': 1, 'sw': 1},\n",
      "                                'params_and_consts': []},\n",
      "               'FParamFun547': {'code': 'def Phi_model(theta, ax,   # inputs\\n'\n",
      "                                        '              g,           # constant '\n",
      "                                        '(gravitational acceleration)\\n'\n",
      "                                        '              c_r          # '\n",
      "                                        'learnable parameter (rolling resist. '\n",
      "                                        'coeff.)\\n'\n",
      "                                        '              ):\\n'\n",
      "                                        '  output = ax + g*torch.sin(theta) + '\n",
      "                                        'c_r*g*torch.cos(theta)\\n'\n",
      "                                        '  return output\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 2,\n",
      "                                'name': 'Phi_model',\n",
      "                                'out_dim': {'dim': 1, 'sw': 1},\n",
      "                                'params_and_consts': ['g', 'c_r']},\n",
      "               'FParamFun550': {'code': 'def y_model(Tyf_engine, Tyf_brake, '\n",
      "                                        'Tyr_brake, vx, ax,  # inputs\\n'\n",
      "                                        '            I_wf, I_wr, r_f, r_r, '\n",
      "                                        'i_gear,              # constants\\n'\n",
      "                                        '            c_v, '\n",
      "                                        'k_d                                   '\n",
      "                                        '# learnable parameters (linear and '\n",
      "                                        'quadratic drag)\\n'\n",
      "                                        '            ):\\n'\n",
      "                                        '  # wheel torques\\n'\n",
      "                                        '  T_yf_traction = Tyf_engine*i_gear\\n'\n",
      "                                        '  T_yf = T_yf_traction - Tyf_brake\\n'\n",
      "                                        '  T_yr = -Tyr_brake\\n'\n",
      "                                        '\\n'\n",
      "                                        '  # analytical model formulation, '\n",
      "                                        'based on the longitudinal vehicle '\n",
      "                                        'dynamics\\n'\n",
      "                                        '  analytical_model = (-2*I_wf*ax/r_f '\n",
      "                                        '+ T_yf)/r_f + \\\\\\n'\n",
      "                                        '                     (-2*I_wr*ax/r_r '\n",
      "                                        '+ T_yr)/r_r - c_v*vx - '\n",
      "                                        'k_d*torch.pow(vx,2)\\n'\n",
      "                                        '\\n'\n",
      "                                        '  # output of the layer\\n'\n",
      "                                        '  output = analytical_model\\n'\n",
      "                                        '  return output\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 5,\n",
      "                                'name': 'y_model',\n",
      "                                'out_dim': {'dim': 1, 'sw': 1},\n",
      "                                'params_and_consts': ['I_wf',\n",
      "                                                      'I_wr',\n",
      "                                                      'r_f',\n",
      "                                                      'r_r',\n",
      "                                                      'i_gear',\n",
      "                                                      'c_v',\n",
      "                                                      'k_d']},\n",
      "               'FParamFun551': {'code': 'def RLS_update(m,    # vehicle mass '\n",
      "                                        'estimate at the previous time step\\n'\n",
      "                                        '               P,    # covariance of '\n",
      "                                        'the estimation error at the previous '\n",
      "                                        'time step\\n'\n",
      "                                        '               Phi,  # regressor at '\n",
      "                                        'the current time step\\n'\n",
      "                                        '               y,    # measurement '\n",
      "                                        'model at the current time step\\n'\n",
      "                                        '               Tyf_engine, Tyf_brake, '\n",
      "                                        'vx,  # inputs\\n'\n",
      "                                        '               i_gear, '\n",
      "                                        'lambda_forget,  # constants\\n'\n",
      "                                        '               Tyf_min_thresh_pos, '\n",
      "                                        'Tyf_min_thresh_neg, vx_min_thresh, '\n",
      "                                        'reg_fact,  # constants\\n'\n",
      "                                        '               ):\\n'\n",
      "                                        '  # compute the total torque at the '\n",
      "                                        'front wheels\\n'\n",
      "                                        '  Tyf = Tyf_engine*i_gear - '\n",
      "                                        'Tyf_brake\\n'\n",
      "                                        '\\n'\n",
      "                                        '  # compute the Kalman gain\\n'\n",
      "                                        '  L = P*Phi / (lambda_forget + '\n",
      "                                        'Phi*P*Phi)\\n'\n",
      "                                        '\\n'\n",
      "                                        '  # update the covariance matrix\\n'\n",
      "                                        '  P_update = (1/lambda_forget) * (P - '\n",
      "                                        'L*Phi*P)\\n'\n",
      "                                        '\\n'\n",
      "                                        '  # validity functions to freeze the '\n",
      "                                        'mass estimate:\\n'\n",
      "                                        '  # validity function for the wheel '\n",
      "                                        'torque: it goes to 0 when Tyf is in '\n",
      "                                        '[Tyf_min_thresh_neg,Tyf_min_thresh_pos], '\n",
      "                                        'and 1 otherwise\\n'\n",
      "                                        '  validity_fun_Tyf = 1.0 + '\n",
      "                                        '(torch.sin(torch.atan((Tyf-Tyf_min_thresh_pos)/reg_fact))+1.0)/2.0 '\n",
      "                                        '- \\\\\\n'\n",
      "                                        '                           '\n",
      "                                        '(torch.sin(torch.atan((Tyf-Tyf_min_thresh_neg)/reg_fact))+1.0)/2.0\\n'\n",
      "                                        '  # vality function for the vehicle '\n",
      "                                        'speed: it goes to 0 when vx is below '\n",
      "                                        'vx_min_thresh, and 1 otherwise\\n'\n",
      "                                        '  validity_fun_vx = '\n",
      "                                        '(torch.sin(torch.atan((vx-vx_min_thresh)/reg_fact))+1.0)/2.0\\n'\n",
      "                                        '  # overall validity function\\n'\n",
      "                                        '  validity_fun = validity_fun_Tyf * '\n",
      "                                        'validity_fun_vx\\n'\n",
      "                                        '\\n'\n",
      "                                        '  # update the vehicle mass estimate\\n'\n",
      "                                        '  m_update = m + L*(y - '\n",
      "                                        'Phi*m)*validity_fun\\n'\n",
      "                                        '\\n'\n",
      "                                        '  # return the updated mass estimate '\n",
      "                                        'and the updated covariance:\\n'\n",
      "                                        '  # concatenate the two tensors along '\n",
      "                                        'the third dimension, but do not add a '\n",
      "                                        'new dimension\\n'\n",
      "                                        '  out_tensor = '\n",
      "                                        'torch.cat((m_update,P_update),dim=2)\\n'\n",
      "                                        '  return out_tensor\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 7,\n",
      "                                'name': 'RLS_update',\n",
      "                                'out_dim': {'dim': 2, 'sw': 1},\n",
      "                                'params_and_consts': ['i_gear',\n",
      "                                                      'lambda_forget',\n",
      "                                                      'Tyf_min_thresh_pos',\n",
      "                                                      'Tyf_min_thresh_neg',\n",
      "                                                      'vx_min_thresh',\n",
      "                                                      'reg_fact']}},\n",
      " 'Inputs': {'Tyf_brake': {'dim': 1, 'sw': [0, 1], 'tw': [0, 0]},\n",
      "            'Tyf_engine': {'dim': 1, 'sw': [0, 1], 'tw': [0, 0]},\n",
      "            'Tyr_brake': {'dim': 1, 'sw': [0, 1], 'tw': [0, 0]},\n",
      "            'ax': {'dim': 1, 'sw': [0, 1], 'tw': [0, 0]},\n",
      "            'm_target': {'dim': 1, 'sw': [0, 1], 'tw': [0, 0]},\n",
      "            'theta': {'dim': 1, 'sw': [0, 1], 'tw': [0, 0]},\n",
      "            'vx': {'dim': 1, 'sw': [0, 1], 'tw': [0, 0]}},\n",
      " 'Outputs': {},\n",
      " 'Parameters': {'c_r': {'dim': 1, 'sw': 1, 'values': [[0.012]]},\n",
      "                'c_v': {'dim': 1, 'sw': 1, 'values': [[0.005]]},\n",
      "                'k_d': {'dim': 1, 'sw': 1, 'values': [[1.001]]}},\n",
      " 'Relations': {'ParamFun1003': ['ParamFun',\n",
      "                                ['SamplePart1002', 'ParamFun949'],\n",
      "                                'FParamFun547'],\n",
      "               'ParamFun1006': ['ParamFun',\n",
      "                                ['ParamFun905',\n",
      "                                 'ParamFun916',\n",
      "                                 'ParamFun927',\n",
      "                                 'ParamFun938',\n",
      "                                 'ParamFun949'],\n",
      "                                'FParamFun550'],\n",
      "               'ParamFun1011': ['ParamFun',\n",
      "                                ['SamplePart1008',\n",
      "                                 'SamplePart1010',\n",
      "                                 'ParamFun1003',\n",
      "                                 'ParamFun1006',\n",
      "                                 'ParamFun905',\n",
      "                                 'ParamFun916',\n",
      "                                 'ParamFun938'],\n",
      "                                'FParamFun551'],\n",
      "               'ParamFun905': ['ParamFun',\n",
      "                               ['SamplePart904', 'Constant498', 'Constant499'],\n",
      "                               'FParamFun495'],\n",
      "               'ParamFun916': ['ParamFun',\n",
      "                               ['SamplePart915', 'Constant503', 'Constant504'],\n",
      "                               'FParamFun500'],\n",
      "               'ParamFun927': ['ParamFun',\n",
      "                               ['SamplePart926', 'Constant508', 'Constant509'],\n",
      "                               'FParamFun505'],\n",
      "               'ParamFun938': ['ParamFun',\n",
      "                               ['SamplePart937', 'Constant513', 'Constant514'],\n",
      "                               'FParamFun510'],\n",
      "               'ParamFun949': ['ParamFun',\n",
      "                               ['SamplePart948', 'Constant518', 'Constant519'],\n",
      "                               'FParamFun515'],\n",
      "               'SamplePart1002': ['SamplePart', ['theta'], [0, 1]],\n",
      "               'SamplePart1008': ['SamplePart', ['m'], [0, 1]],\n",
      "               'SamplePart1010': ['SamplePart', ['P'], [0, 1]],\n",
      "               'SamplePart1015': ['SamplePart', ['m_target'], [0, 1]],\n",
      "               'SamplePart904': ['SamplePart', ['Tyf_engine'], [0, 1]],\n",
      "               'SamplePart915': ['SamplePart', ['Tyf_brake'], [0, 1]],\n",
      "               'SamplePart926': ['SamplePart', ['Tyr_brake'], [0, 1]],\n",
      "               'SamplePart937': ['SamplePart', ['vx'], [0, 1]],\n",
      "               'SamplePart948': ['SamplePart', ['ax'], [0, 1]],\n",
      "               'Select1012': ['Select', ['ParamFun1011'], 0],\n",
      "               'Select1013': ['Select', ['ParamFun1011'], 1]},\n",
      " 'SampleTime': 1,\n",
      " 'States': {'P': {'closedLoop': 'Select1013',\n",
      "                  'dim': 1,\n",
      "                  'sw': [0, 1],\n",
      "                  'tw': [0, 0]},\n",
      "            'm': {'closedLoop': 'Select1012',\n",
      "                  'dim': 1,\n",
      "                  'sw': [0, 1],\n",
      "                  'tw': [0, 0]}}}\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create a neu4mes model\n",
    "mass_estimator = Neu4mes(visualizer='Standard',seed=12,workspace=os.path.join(os.getcwd(),'trained_models'))  #visualizer=MPLVisulizer()\n",
    "\n",
    "# Add the neural model to the neu4mes structure and neuralization of the model\n",
    "mass_estimator.addModel('mass_estim',[m_estim,P_estim])\n",
    "mass_estimator.addMinimize('mass_error', \n",
    "                           m_target.next(),  # next means the first value in the \"future\"\n",
    "                           m_estim, \n",
    "                           loss_function='mse')\n",
    "mass_estimator.neuralizeModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCannot read file /Users/mattiapiccinini/Documents/Research/Neu4Mes/Neu4Mes/tutorials/datasets/estimate_vehicle_mass/training/.DS_Store\u001b[0m\n",
      "\u001b[1;32m============================ Neu4mes Model Dataset =============================\u001b[0m\n",
      "\u001b[32mDataset Name:                 training_set\u001b[0m\n",
      "\u001b[32mNumber of files:              2\u001b[0m\n",
      "\u001b[32mTotal number of samples:      1109\u001b[0m\n",
      "\u001b[32mShape of vx:                  (1109, 1, 1)\u001b[0m\n",
      "\u001b[32mShape of Tyf_brake:           (1109, 1, 1)\u001b[0m\n",
      "\u001b[32mShape of Tyf_engine:          (1109, 1, 1)\u001b[0m\n",
      "\u001b[32mShape of ax:                  (1109, 1, 1)\u001b[0m\n",
      "\u001b[32mShape of Tyr_brake:           (1109, 1, 1)\u001b[0m\n",
      "\u001b[32mShape of theta:               (1109, 1, 1)\u001b[0m\n",
      "\u001b[32mShape of m_target:            (1109, 1, 1)\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[33mCannot read file /Users/mattiapiccinini/Documents/Research/Neu4Mes/Neu4Mes/tutorials/datasets/estimate_vehicle_mass/validation/.DS_Store\u001b[0m\n",
      "\u001b[1;32m============================ Neu4mes Model Dataset =============================\u001b[0m\n",
      "\u001b[32mDataset Name:                 validation_set\u001b[0m\n",
      "\u001b[32mNumber of files:              2\u001b[0m\n",
      "\u001b[32mTotal number of samples:      1109\u001b[0m\n",
      "\u001b[32mShape of vx:                  (1109, 1, 1)\u001b[0m\n",
      "\u001b[32mShape of Tyf_brake:           (1109, 1, 1)\u001b[0m\n",
      "\u001b[32mShape of Tyf_engine:          (1109, 1, 1)\u001b[0m\n",
      "\u001b[32mShape of ax:                  (1109, 1, 1)\u001b[0m\n",
      "\u001b[32mShape of Tyr_brake:           (1109, 1, 1)\u001b[0m\n",
      "\u001b[32mShape of theta:               (1109, 1, 1)\u001b[0m\n",
      "\u001b[32mShape of m_target:            (1109, 1, 1)\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Structure to extract the inputs and outputs from the training and validation datasets\n",
    "data_struct = ['',('m','m_target'),'P','Tyf_engine','Tyf_brake','Tyr_brake',  \n",
    "               'theta','vx','ax','ay','steer']  # both mass and mass_target are read from the same column of the csv file\n",
    "\n",
    "# Pass the training and the validation datasets to the neu4mes structure\n",
    "mass_estimator.loadData(name='training_set', source=data_folder_train, format=data_struct, skiplines=1)\n",
    "mass_estimator.loadData(name='validation_set', source=data_folder_valid, format=data_struct, skiplines=1)\n",
    "\n",
    "# check the definition of the windows in the inputs and outputs\n",
    "#samples_test_set = mass_estimator.get_samples('training_set', index=100, window=1) \n",
    "#print(samples_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the NN in closed-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mRecurrent train: update States variables ['m', 'P'] for 900 samples\u001b[0m\n",
      "\u001b[1;32m======================== Neu4mes Model Train Parameters ========================\u001b[0m\n",
      "\u001b[32mmodels:                       ['mass_estim']\u001b[0m\n",
      "\u001b[32mtrain dataset:                training_set\u001b[0m\n",
      "\u001b[32mtrain {batch size, samples}:  {200, 1109}\u001b[0m\n",
      "\u001b[32mval dataset:                  validation_set\u001b[0m\n",
      "\u001b[32mval {batch size, samples}:    {200, 1109}\u001b[0m\n",
      "\u001b[32mnum of epochs:                40\u001b[0m\n",
      "\u001b[32mshuffle data:                 True\u001b[0m\n",
      "\u001b[32mearly stopping:               early_stop_patience\u001b[0m\n",
      "\u001b[32mearly stopping params:        {'error': 'mass_error', 'patience': 100}\u001b[0m\n",
      "\u001b[32mminimize:                     {'mass_error': {'A': 'SamplePart1015',\n",
      "                                              'B': 'Select1012',\n",
      "                                              'loss': 'mse'}}\u001b[0m\n",
      "\u001b[32mprediction samples:           900\u001b[0m\n",
      "\u001b[32mstep:                         900\u001b[0m\n",
      "\u001b[32mclosed loop:                  {}\u001b[0m\n",
      "\u001b[32mconnect:                      {}\u001b[0m\n",
      "\u001b[32moptimizer:                    Adam\u001b[0m\n",
      "\u001b[32moptimizer defaults:           {'lr': 0.001}\u001b[0m\n",
      "\u001b[32moptimizer params:             [{'params': 'c_r'},\n",
      "                               {'params': 'c_v'},\n",
      "                               {'params': 'k_d'}]\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n",
      "\u001b[1;32m================= Neu4mes Training =================\u001b[0m\n",
      "\u001b[32m|  Epoch   |\u001b[0m\u001b[32m     mass_error    |\u001b[0m\u001b[32m       Total       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m        Loss       |\u001b[0m\u001b[32m        Loss       |\u001b[0m\n",
      "\u001b[32m|          |\u001b[0m\u001b[32m  train  |\u001b[0m\u001b[32m   val   |\u001b[0m\u001b[32m  train  |\u001b[0m\u001b[32m   val   |\u001b[0m\n",
      "\u001b[32m|--------------------------------------------------|\u001b[0m\n",
      "\u001b[32m|  10/40   |\u001b[0m\u001b[32m  0.e+00 |\u001b[0m\u001b[32m6.727e+03|\u001b[0m\u001b[32m  0.e+00 |\u001b[0m\u001b[32m6.727e+03|\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m predict_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m900\u001b[39m  \u001b[38;5;66;03m# number of samples after which the internal state is reset\u001b[39;00m\n\u001b[1;32m     10\u001b[0m steps_skip \u001b[38;5;241m=\u001b[39m predict_samples \u001b[38;5;66;03m#1  # number of samples to skip when going to a new window. The default is 1, meaning the size of a batch. If steps_skip = predict_samples, then the whole window size is skipped\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m train_result_open_loop \u001b[38;5;241m=\u001b[39m \u001b[43mmass_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining_set\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation_set\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mtraining_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_pars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAdam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearlystopping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stop_patience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mearly_stopping_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mearly_stop_patience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43merror\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmass_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mprediction_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_skip\u001b[49m\u001b[43m)\u001b[49m  \n",
      "File \u001b[0;32m~/Documents/Research/Neu4Mes/Neu4Mes/tutorials/../neu4mes/neu4mes.py:862\u001b[0m, in \u001b[0;36mNeu4mes.trainModel\u001b[0;34m(self, models, train_dataset, validation_dataset, test_dataset, splits, closed_loop, connect, step, prediction_samples, shuffle_data, early_stopping, early_stopping_params, minimize_gain, num_of_epochs, train_batch_size, val_batch_size, test_batch_size, optimizer, lr, lr_param, optimizer_params, optimizer_defaults, training_params, add_optimizer_params, add_optimizer_defaults)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurrent_train:\n\u001b[0;32m--> 862\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__recurrentTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXY_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimize_gain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosed_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__Train(XY_val, n_samples_val, val_batch_size, minimize_gain, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/Research/Neu4Mes/Neu4Mes/tutorials/../neu4mes/neu4mes.py:941\u001b[0m, in \u001b[0;36mNeu4mes.__recurrentTrain\u001b[0;34m(self, data, n_samples, batch_size, loss_gains, prediction_samples, closed_loop, step, connect, shuffle, train)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mreset_connect_variables(connect, XY, only\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m horizon_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(prediction_samples \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 941\u001b[0m     out, minimize_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXY\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m## Forward pass\u001b[39;00m\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_internal:\n\u001b[1;32m    943\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__save_internal(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minout_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(idx)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(horizon_idx),{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXY\u001b[39m\u001b[38;5;124m'\u001b[39m:XY,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m:out,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstates,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mall_parameters,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnect\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconnect_variables})\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neu4mes/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neu4mes/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Research/Neu4Mes/Neu4Mes/tutorials/../neu4mes/model.py:178\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m         layer_inputs\u001b[38;5;241m.\u001b[39mappend(result_dict[key])\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m## Execute the current relation\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m result_dict[relation] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelation_forward\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrelation\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlayer_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m available_keys\u001b[38;5;241m.\u001b[39madd(relation)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m## Update the connect variables if necessary\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neu4mes/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neu4mes/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Research/Neu4Mes/Neu4Mes/tutorials/../neu4mes/parametricfunction.py:269\u001b[0m, in \u001b[0;36mParametric_Layer.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_over_batch:\n\u001b[1;32m    268\u001b[0m     function_to_call \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfunc\u001b[38;5;241m.\u001b[39mvmap(function_to_call,in_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_map_dim)\n\u001b[0;32m--> 269\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_to_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m<string>:7\u001b[0m, in \u001b[0;36mPhi_model\u001b[0;34m(theta, ax, g, c_r)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "batch_size = 200\n",
    "learn_rate = 1e-3  # learning rate\n",
    "early_stop_patience = 100\n",
    "training_pars = {'num_of_epochs':num_epochs, \n",
    "                 'val_batch_size':batch_size, \n",
    "                 'train_batch_size':batch_size, \n",
    "                 'lr':learn_rate}\n",
    "predict_samples = 900  # number of samples after which the internal state is reset\n",
    "steps_skip = predict_samples #1  # number of samples to skip when going to a new window. The default is 1, meaning the size of a batch. If steps_skip = predict_samples, then the whole window size is skipped\n",
    "\n",
    "train_result_open_loop = mass_estimator.trainModel(train_dataset='training_set', validation_dataset='validation_set', \n",
    "                                                   training_params=training_pars, optimizer='Adam', shuffle_data=True,\n",
    "                                                   early_stopping=earlystopping.early_stop_patience,  \n",
    "                                                   early_stopping_params={'patience':early_stop_patience,\n",
    "                                                                          'error':'mass_error'},\n",
    "                                                   prediction_samples=predict_samples, step=steps_skip)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m================================ Neu4mes Model =================================\u001b[0m\n",
      "\u001b[32m{'Constants': {'Constant360': {'dim': 1, 'values': 0.0},\n",
      "               'Constant361': {'dim': 1, 'values': 378.9961321254068},\n",
      "               'Constant365': {'dim': 1, 'values': 0.0},\n",
      "               'Constant366': {'dim': 1, 'values': 3034.740976853754},\n",
      "               'Constant370': {'dim': 1, 'values': 0.0},\n",
      "               'Constant371': {'dim': 1, 'values': 1114.470293868032},\n",
      "               'Constant375': {'dim': 1, 'values': 4.0},\n",
      "               'Constant376': {'dim': 1, 'values': 20.627002395766304},\n",
      "               'Constant380': {'dim': 1, 'values': -1.5607289739112873},\n",
      "               'Constant381': {'dim': 1, 'values': 2.746621294865885},\n",
      "               'I_wf': {'dim': 1, 'values': 2.4},\n",
      "               'I_wr': {'dim': 1, 'values': 2.4},\n",
      "               'Tyf_min_thresh_neg': {'dim': 1, 'values': -200},\n",
      "               'Tyf_min_thresh_pos': {'dim': 1, 'values': 200},\n",
      "               'g': {'dim': 1, 'values': 9.81},\n",
      "               'i_gear': {'dim': 1, 'values': 10.163},\n",
      "               'lambda_forget': {'dim': 1, 'values': 0.995},\n",
      "               'r_f': {'dim': 1, 'values': 0.364},\n",
      "               'r_r': {'dim': 1, 'values': 0.363},\n",
      "               'reg_fact': {'dim': 1, 'values': 0.03},\n",
      "               'vx_min_thresh': {'dim': 1, 'values': 4.0}},\n",
      " 'Functions': {'FParamFun357': {'code': 'def sat_fun(x,x_min,x_max):\\n'\n",
      "                                        '  return '\n",
      "                                        'torch.min(torch.max(x,x_min),x_max)\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 3,\n",
      "                                'name': 'sat_fun',\n",
      "                                'out_dim': {'dim': 1, 'sw': 1},\n",
      "                                'params_and_consts': []},\n",
      "               'FParamFun362': {'code': 'def sat_fun(x,x_min,x_max):\\n'\n",
      "                                        '  return '\n",
      "                                        'torch.min(torch.max(x,x_min),x_max)\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 3,\n",
      "                                'name': 'sat_fun',\n",
      "                                'out_dim': {'dim': 1, 'sw': 1},\n",
      "                                'params_and_consts': []},\n",
      "               'FParamFun367': {'code': 'def sat_fun(x,x_min,x_max):\\n'\n",
      "                                        '  return '\n",
      "                                        'torch.min(torch.max(x,x_min),x_max)\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 3,\n",
      "                                'name': 'sat_fun',\n",
      "                                'out_dim': {'dim': 1, 'sw': 1},\n",
      "                                'params_and_consts': []},\n",
      "               'FParamFun372': {'code': 'def sat_fun(x,x_min,x_max):\\n'\n",
      "                                        '  return '\n",
      "                                        'torch.min(torch.max(x,x_min),x_max)\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 3,\n",
      "                                'name': 'sat_fun',\n",
      "                                'out_dim': {'dim': 1, 'sw': 1},\n",
      "                                'params_and_consts': []},\n",
      "               'FParamFun377': {'code': 'def sat_fun(x,x_min,x_max):\\n'\n",
      "                                        '  return '\n",
      "                                        'torch.min(torch.max(x,x_min),x_max)\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 3,\n",
      "                                'name': 'sat_fun',\n",
      "                                'out_dim': {'dim': 1, 'sw': 1},\n",
      "                                'params_and_consts': []},\n",
      "               'FParamFun409': {'code': 'def Phi_model(theta, ax,   # inputs\\n'\n",
      "                                        '              g,           # constant '\n",
      "                                        '(gravitational acceleration)\\n'\n",
      "                                        '              c_r          # '\n",
      "                                        'learnable parameter (rolling resist. '\n",
      "                                        'coeff.)\\n'\n",
      "                                        '              ):\\n'\n",
      "                                        '  output = ax + g*torch.sin(theta) + '\n",
      "                                        'c_r*g*torch.cos(theta)\\n'\n",
      "                                        '  return output\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 2,\n",
      "                                'name': 'Phi_model',\n",
      "                                'out_dim': {'dim': 1, 'sw': 1},\n",
      "                                'params_and_consts': ['g', 'c_r']},\n",
      "               'FParamFun412': {'code': 'def y_model(Tyf_engine, Tyf_brake, '\n",
      "                                        'Tyr_brake, vx, ax,  # inputs\\n'\n",
      "                                        '            I_wf, I_wr, r_f, r_r, '\n",
      "                                        'i_gear,              # constants\\n'\n",
      "                                        '            c_v, '\n",
      "                                        'k_d                                   '\n",
      "                                        '# learnable parameters (linear and '\n",
      "                                        'quadratic drag)\\n'\n",
      "                                        '            ):\\n'\n",
      "                                        '  # wheel torques\\n'\n",
      "                                        '  T_yf_traction = Tyf_engine*i_gear\\n'\n",
      "                                        '  T_yf = T_yf_traction - Tyf_brake\\n'\n",
      "                                        '  T_yr = -Tyr_brake\\n'\n",
      "                                        '\\n'\n",
      "                                        '  # analytical model formulation, '\n",
      "                                        'based on the longitudinal vehicle '\n",
      "                                        'dynamics\\n'\n",
      "                                        '  analytical_model = (-2*I_wf*ax/r_f '\n",
      "                                        '+ T_yf)/r_f + \\\\\\n'\n",
      "                                        '                     (-2*I_wr*ax/r_r '\n",
      "                                        '+ T_yr)/r_r - c_v*vx - '\n",
      "                                        'k_d*torch.pow(vx,2)\\n'\n",
      "                                        '\\n'\n",
      "                                        '  # output of the layer\\n'\n",
      "                                        '  output = analytical_model\\n'\n",
      "                                        '  return output\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 5,\n",
      "                                'name': 'y_model',\n",
      "                                'out_dim': {'dim': 1, 'sw': 1},\n",
      "                                'params_and_consts': ['I_wf',\n",
      "                                                      'I_wr',\n",
      "                                                      'r_f',\n",
      "                                                      'r_r',\n",
      "                                                      'i_gear',\n",
      "                                                      'c_v',\n",
      "                                                      'k_d']},\n",
      "               'FParamFun413': {'code': 'def RLS_update(m,    # vehicle mass '\n",
      "                                        'estimate at the previous time step\\n'\n",
      "                                        '               P,    # covariance of '\n",
      "                                        'the estimation error at the previous '\n",
      "                                        'time step\\n'\n",
      "                                        '               Phi,  # regressor at '\n",
      "                                        'the current time step\\n'\n",
      "                                        '               y,    # measurement '\n",
      "                                        'model at the current time step\\n'\n",
      "                                        '               Tyf_engine, Tyf_brake, '\n",
      "                                        'vx,  # inputs\\n'\n",
      "                                        '               i_gear, '\n",
      "                                        'lambda_forget,  # constants\\n'\n",
      "                                        '               Tyf_min_thresh_pos, '\n",
      "                                        'Tyf_min_thresh_neg, vx_min_thresh, '\n",
      "                                        'reg_fact,  # constants\\n'\n",
      "                                        '               ):\\n'\n",
      "                                        '  # compute the total torque at the '\n",
      "                                        'front wheels\\n'\n",
      "                                        '  Tyf = Tyf_engine*i_gear - '\n",
      "                                        'Tyf_brake\\n'\n",
      "                                        '\\n'\n",
      "                                        '  # compute the Kalman gain\\n'\n",
      "                                        '  L = P*Phi / (lambda_forget + '\n",
      "                                        'Phi*P*Phi)\\n'\n",
      "                                        '\\n'\n",
      "                                        '  # update the covariance matrix\\n'\n",
      "                                        '  P_update = (1/lambda_forget) * (P - '\n",
      "                                        'L*Phi*P)\\n'\n",
      "                                        '\\n'\n",
      "                                        '  # validity functions to freeze the '\n",
      "                                        'mass estimate:\\n'\n",
      "                                        '  # validity function for the wheel '\n",
      "                                        'torque: it goes to 0 when Tyf is in '\n",
      "                                        '[Tyf_min_thresh_neg,Tyf_min_thresh_pos], '\n",
      "                                        'and 1 otherwise\\n'\n",
      "                                        '  validity_fun_Tyf = 1.0 + '\n",
      "                                        '(torch.sin(torch.atan((Tyf-Tyf_min_thresh_pos)/reg_fact))+1.0)/2.0 '\n",
      "                                        '- \\\\\\n'\n",
      "                                        '                           '\n",
      "                                        '(torch.sin(torch.atan((Tyf-Tyf_min_thresh_neg)/reg_fact))+1.0)/2.0\\n'\n",
      "                                        '  # vality function for the vehicle '\n",
      "                                        'speed: it goes to 0 when vx is below '\n",
      "                                        'vx_min_thresh, and 1 otherwise\\n'\n",
      "                                        '  validity_fun_vx = '\n",
      "                                        '(torch.sin(torch.atan((vx-vx_min_thresh)/reg_fact))+1.0)/2.0\\n'\n",
      "                                        '  # overall validity function\\n'\n",
      "                                        '  validity_fun = validity_fun_Tyf * '\n",
      "                                        'validity_fun_vx\\n'\n",
      "                                        '\\n'\n",
      "                                        '  # update the vehicle mass estimate\\n'\n",
      "                                        '  m_update = m + L*(y - '\n",
      "                                        'Phi*m)*validity_fun\\n'\n",
      "                                        '\\n'\n",
      "                                        '  # return the updated mass estimate '\n",
      "                                        'and the updated covariance:\\n'\n",
      "                                        '  # concatenate the two tensors along '\n",
      "                                        'the third dimension, but do not add a '\n",
      "                                        'new dimension\\n'\n",
      "                                        '  out_tensor = '\n",
      "                                        'torch.cat((m_update,P_update),dim=2)\\n'\n",
      "                                        '  return out_tensor\\n',\n",
      "                                'map_over_dim': False,\n",
      "                                'n_input': 7,\n",
      "                                'name': 'RLS_update',\n",
      "                                'out_dim': {'dim': 2, 'sw': 1},\n",
      "                                'params_and_consts': ['i_gear',\n",
      "                                                      'lambda_forget',\n",
      "                                                      'Tyf_min_thresh_pos',\n",
      "                                                      'Tyf_min_thresh_neg',\n",
      "                                                      'vx_min_thresh',\n",
      "                                                      'reg_fact']}},\n",
      " 'Inputs': {'Tyf_brake': {'dim': 1, 'sw': [0, 1], 'tw': [0, 0]},\n",
      "            'Tyf_engine': {'dim': 1, 'sw': [0, 1], 'tw': [0, 0]},\n",
      "            'Tyr_brake': {'dim': 1, 'sw': [0, 1], 'tw': [0, 0]},\n",
      "            'ax': {'dim': 1, 'sw': [0, 1], 'tw': [0, 0]},\n",
      "            'm_target': {'dim': 1, 'sw': [0, 1], 'tw': [0, 0]},\n",
      "            'theta': {'dim': 1, 'sw': [0, 1], 'tw': [0, 0]},\n",
      "            'vx': {'dim': 1, 'sw': [0, 1], 'tw': [0, 0]}},\n",
      " 'Outputs': {},\n",
      " 'Parameters': {'c_r': {'dim': 1, 'sw': 1, 'values': [[0.00871707871556282]]},\n",
      "                'c_v': {'dim': 1, 'sw': 1, 'values': [[0.0024972904939204454]]},\n",
      "                'k_d': {'dim': 1, 'sw': 1, 'values': [[0.9982839226722717]]}},\n",
      " 'Relations': {'ParamFun651': ['ParamFun',\n",
      "                               ['SamplePart650', 'Constant360', 'Constant361'],\n",
      "                               'FParamFun357'],\n",
      "               'ParamFun662': ['ParamFun',\n",
      "                               ['SamplePart661', 'Constant365', 'Constant366'],\n",
      "                               'FParamFun362'],\n",
      "               'ParamFun673': ['ParamFun',\n",
      "                               ['SamplePart672', 'Constant370', 'Constant371'],\n",
      "                               'FParamFun367'],\n",
      "               'ParamFun684': ['ParamFun',\n",
      "                               ['SamplePart683', 'Constant375', 'Constant376'],\n",
      "                               'FParamFun372'],\n",
      "               'ParamFun695': ['ParamFun',\n",
      "                               ['SamplePart694', 'Constant380', 'Constant381'],\n",
      "                               'FParamFun377'],\n",
      "               'ParamFun749': ['ParamFun',\n",
      "                               ['SamplePart748', 'ParamFun695'],\n",
      "                               'FParamFun409'],\n",
      "               'ParamFun752': ['ParamFun',\n",
      "                               ['ParamFun651',\n",
      "                                'ParamFun662',\n",
      "                                'ParamFun673',\n",
      "                                'ParamFun684',\n",
      "                                'ParamFun695'],\n",
      "                               'FParamFun412'],\n",
      "               'ParamFun757': ['ParamFun',\n",
      "                               ['SamplePart754',\n",
      "                                'SamplePart756',\n",
      "                                'ParamFun749',\n",
      "                                'ParamFun752',\n",
      "                                'ParamFun651',\n",
      "                                'ParamFun662',\n",
      "                                'ParamFun684'],\n",
      "                               'FParamFun413'],\n",
      "               'SamplePart650': ['SamplePart', ['Tyf_engine'], [0, 1]],\n",
      "               'SamplePart661': ['SamplePart', ['Tyf_brake'], [0, 1]],\n",
      "               'SamplePart672': ['SamplePart', ['Tyr_brake'], [0, 1]],\n",
      "               'SamplePart683': ['SamplePart', ['vx'], [0, 1]],\n",
      "               'SamplePart694': ['SamplePart', ['ax'], [0, 1]],\n",
      "               'SamplePart748': ['SamplePart', ['theta'], [0, 1]],\n",
      "               'SamplePart754': ['SamplePart', ['m'], [0, 1]],\n",
      "               'SamplePart756': ['SamplePart', ['P'], [0, 1]],\n",
      "               'SamplePart761': ['SamplePart', ['m_target'], [0, 1]],\n",
      "               'Select758': ['Select', ['ParamFun757'], 0],\n",
      "               'Select759': ['Select', ['ParamFun757'], 1]},\n",
      " 'SampleTime': 1,\n",
      " 'States': {'P': {'closedLoop': 'Select759',\n",
      "                  'dim': 1,\n",
      "                  'sw': [0, 1],\n",
      "                  'tw': [0, 0]},\n",
      "            'm': {'closedLoop': 'Select758',\n",
      "                  'dim': 1,\n",
      "                  'sw': [0, 1],\n",
      "                  'tw': [0, 0]}}}\u001b[0m\n",
      "\u001b[32m================================================================================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Print the trained NN parameters\n",
    "mass_estimator.neuralizeModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mass_estim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m mass_estimator\u001b[38;5;241m.\u001b[39mresetStates()  \u001b[38;5;66;03m# reset the internal state\u001b[39;00m\n\u001b[1;32m      5\u001b[0m out_nn_test_set         \u001b[38;5;241m=\u001b[39m mass_estimator(samples_test_set, sampled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      6\u001b[0m                                          prediction_samples\u001b[38;5;241m=\u001b[39mnum_samples_use)  \n\u001b[0;32m----> 7\u001b[0m out_nn_test_set_extract \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mout_nn_test_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmass_estim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Extract the samples\u001b[39;00m\n\u001b[1;32m     10\u001b[0m samples_test_set_extract \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(samples_test_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm_target\u001b[39m\u001b[38;5;124m'\u001b[39m]),\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mass_estim'"
     ]
    }
   ],
   "source": [
    "# Test on a new dataset\n",
    "num_samples_use  = 200\n",
    "samples_test_set = mass_estimator.getSamples('validation_set', index=0, window=num_samples_use) \n",
    "mass_estimator.resetStates()  # reset the internal state\n",
    "out_nn_test_set         = mass_estimator(samples_test_set, sampled=True, \n",
    "                                         prediction_samples=num_samples_use)  \n",
    "out_nn_test_set_extract = np.asarray(out_nn_test_set['mass_estim'])\n",
    "\n",
    "# Extract the samples\n",
    "samples_test_set_extract = np.zeros((len(samples_test_set['m_target']),1))\n",
    "for i in range(0,len(samples_test_set_extract)):\n",
    "  samples_test_set_extract[i] = samples_test_set['m_target'][i]\n",
    "\n",
    "# Compute the MSE on the test set\n",
    "mse_calc = 0\n",
    "for i in range(0,len(samples_test_set_extract)):\n",
    "  mse_calc = mse_calc + (samples_test_set_extract[i] - out_nn_test_set_extract[i])**2 \n",
    "mse_calc = mse_calc/len(samples_test_set_extract)\n",
    "print('MSE on the test set: ', mse_calc, ' kg^2')\n",
    "\n",
    "flag_plot_results = True\n",
    "if flag_plot_results:\n",
    "  # plot the results\n",
    "  plt.figure()\n",
    "  plt.plot(samples_test_set_extract,label='Target',linewidth=2)\n",
    "  plt.plot(out_nn_test_set_extract,label='NN',linestyle='--',linewidth=2)\n",
    "  plt.xlabel('Sample')\n",
    "  plt.ylabel('Vehicle mass [kg]')\n",
    "  plt.legend()\n",
    "  plt.grid()\n",
    "  plt.show()\n",
    "\n",
    "# Test with custom data\n",
    "#mass_estimator({'curv':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],'steer':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the trained NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_export_trained_model = False\n",
    "if flag_export_trained_model:\n",
    "  # Export the model\n",
    "  mass_estimator.neuralizeModel()\n",
    "  mass_estimator.exportJSON()\n",
    "\n",
    "flag_load_trained_model = False\n",
    "if flag_load_trained_model:\n",
    "  # Reload the trained model:\n",
    "  # Load the json file with the model\n",
    "  json_folder = os.path.join(os.getcwd(),'tutorials','trained_models','neu4mes_2024_10_07_17_50')\n",
    "  json_file = os.path.join(json_folder,'model.json')\n",
    "  import json\n",
    "  # Open and read the JSON file\n",
    "  with open(json_file, 'r') as file:\n",
    "      model_trained_json = json.load(file)\n",
    "\n",
    "  mass_estimator.model_def = model_trained_json\n",
    "  # mass_estimator.trainModel(train_dataset='training_set', validation_dataset='validation_set', \n",
    "  #                                  training_params=training_pars_closed_loop, optimizer='Adam', shuffle_data=True,\n",
    "  #                                  prediction_samples=predict_samples, step=steps_skip,\n",
    "  #                                  early_stopping=earlystopping.early_stop_valid_patience, early_stopping_params={'exit_tol':1-3})  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "neu4mes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
